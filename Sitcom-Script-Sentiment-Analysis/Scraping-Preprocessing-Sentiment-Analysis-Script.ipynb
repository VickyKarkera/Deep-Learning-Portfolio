{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Installing required packages"
      ],
      "metadata": {
        "id": "NR8dUtvdZJPI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZo0NAF4Y6PO",
        "outputId": "604a7db0-9763-4d5c-ae04-37a81f1a41b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers requests beautifulsoup4 pandas numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv_-QFQ4ZTLt",
        "outputId": "dccff233-2374-44f9-8420-e00c0b26e69d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Importing required packages"
      ],
      "metadata": {
        "id": "_aFXYP0-ZgLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "Zmx6PHAwZkSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Data scraping"
      ],
      "metadata": {
        "id": "GV5dRPVNZnXt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scraping links to all scripts for every episode in the show."
      ],
      "metadata": {
        "id": "VFkxo_PdaAs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "episode_nav = pd.DataFrame(columns=[\"Season\",\"Episode\",\"Title\",\"URL\"])\n",
        "\n",
        "#links to pages with multiple episodes scripts\n",
        "pages_arr = [\"https://transcripts.foreverdreaming.org/viewforum.php?f=845\",\"https://transcripts.foreverdreaming.org/viewforum.php?f=845&start=78\",\"https://transcripts.foreverdreaming.org/viewforum.php?f=845&start=156\"]\n",
        "\n",
        "#iterating over all pages\n",
        "for page in pages_arr:\n",
        "  # scraping data from script website\n",
        "  r = requests.get(page)\n",
        "  soup = BeautifulSoup(r.text,'html.parser')\n",
        "  regex = re.compile('.*topictitle.*')\n",
        "  results = soup.find_all('a',{'class':regex})\n",
        "  results = results[1:]\n",
        "\n",
        "  for i in range(0,len(results)):\n",
        "    # extracting a link to a single episode and constructing valid url\n",
        "    templink = results[i].attrs[\"href\"]\n",
        "    templink = re.findall(r\"viewtopic.php\\?t=\\d+\",templink)\n",
        "    link= \"https://transcripts.foreverdreaming.org/\" + templink[0]\n",
        "    # extracting name, episode number and season number\n",
        "    temptitle = results[i].text\n",
        "    name = re.split(r\"-\",temptitle)\n",
        "    season, episode = re.split(r\"x\",name[0])\n",
        "    name = name[1]\n",
        "    episode_nav.loc[len(episode_nav.index)] = [season,episode,name,link]\n",
        "\n",
        "episode_nav = episode_nav.loc[2:]\n",
        "episode_nav = episode_nav.iloc[::-1]\n",
        "episode_nav.reset_index(inplace=True,drop=True)"
      ],
      "metadata": {
        "id": "gwAwx2_bZs2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Attaching sentiment to each episode"
      ],
      "metadata": {
        "id": "7ig2xj6faJb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT sentiment analysis model to detect emotions\n",
        "classifier = pipeline(\"text-classification\",model='bhadresh-savani/bert-base-uncased-emotion', return_all_scores=True)\n",
        "\n",
        "# function to get primary emotion conveyed in text from pretrained Bert classfier model.\n",
        "def emotion_detector(line):\n",
        "  prediction = classifier(line)\n",
        "  max = 0\n",
        "  for i in range(0,len(prediction[0])):\n",
        "    if prediction[0][i][\"score\"] > max:\n",
        "      max = prediction[0][i][\"score\"]\n",
        "      strongest_emotion= prediction[0][i][\"label\"]\n",
        "  return strongest_emotion\n",
        "\n",
        "# dataframe that stores emotion percentage\n",
        "episode_emo = pd.DataFrame(columns=['joy', 'anger', 'fear', 'sadness', 'love', 'surprise'])\n",
        "\n",
        "# iterate over all episode links\n",
        "for link in episode_nav[\"URL\"]:\n",
        "\n",
        "# STEP 1: collect script data into dataframe format\n",
        "  # scraping script for single episode\n",
        "  r = requests.get(link)\n",
        "  soup = BeautifulSoup(r.text,'html.parser')\n",
        "  regex = re.compile('.*content.*')\n",
        "  results = soup.find_all('div',{'class':regex})\n",
        "  text = results[1].text # transcript of episode stored here\n",
        "  refined_script = pd.DataFrame(columns=['character','dialogue']) # Dataframe to store final script data\n",
        "  # get dialogues spoken by selected characters\n",
        "  script = re.findall(r'(\\nJoey.*|\\nMonica.*|\\nChandler.*|\\nPhoebe.*|\\nRoss.*|\\nRachel.*|\\nJOEY.*|\\nMONICA.*|\\nCHANDLER.*|\\nPHOEBE.*|\\nROSS.*|\\nRACHEL.*)',text)\n",
        "  # reformat lines into speaker and dialogue spoken\n",
        "  for line in script:\n",
        "    line_temp = re.split(r\":|;\",line,maxsplit=1)\n",
        "    line_temp[0] = re.sub(\"\\n\",'',line_temp[0])\n",
        "    if len(line_temp) == 2:\n",
        "      refined_script.loc[len(refined_script.index)] = line_temp\n",
        "\n",
        "# STEP 2: Apply sentiment analysis model on each dialogue spoken\n",
        "  # apply sentiment analysis model to each dialogue\n",
        "  refined_script['sentiment'] = refined_script['dialogue'].apply(lambda x: emotion_detector(x[:]))\n",
        "\n",
        "  # for every emotion detected in script provide the percentage of that emotion\n",
        "  for emotion in (round(refined_script[\"sentiment\"].value_counts(normalize=True)*100).keys().tolist()):\n",
        "    emotion_holder = round(refined_script[\"sentiment\"].value_counts(normalize=True)*100)\n",
        "    if emotion == \"joy\":\n",
        "      joy = emotion_holder[\"joy\"]\n",
        "    elif emotion == \"anger\":\n",
        "      anger = emotion_holder[\"anger\"]\n",
        "    elif emotion == \"fear\":\n",
        "      fear = emotion_holder[\"fear\"]\n",
        "    elif emotion == \"sadness\":\n",
        "      sadness = emotion_holder[\"sadness\"]\n",
        "    elif emotion == \"love\":\n",
        "      love = emotion_holder[\"love\"]\n",
        "    elif emotion == \"surprise\":\n",
        "      surprise = emotion_holder[\"surprise\"]\n",
        "\n",
        "  # append values for each sentiment\n",
        "  episode_emo.loc[len(episode_emo.index)] = [joy, anger, fear, sadness, love, surprise]"
      ],
      "metadata": {
        "id": "izQNfjI8ahh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "combining the episode data with emotion data"
      ],
      "metadata": {
        "id": "f3QLLmQldjJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "friends_emotion_data = pd.concat([episode_nav,episode_emo],axis=1)\n",
        "\n",
        "# creating final dataset\n",
        "friends_emotion_data.to_excel(\"final_friends_data.xlsx\")"
      ],
      "metadata": {
        "id": "Guh3BvnFdcBB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}